= Asgard 2 Platform: Kato
Dan Woods <danw@netflix.com>
2013-05-12
:appversion: 1.1-SNAPSHOT
:source-highlighter: prettify

== Getting Started

Kato is built as a multi-module Gradle project, which allows its component parts to exist irrespective of one another. This modularity affords for various facets of a cloud deployment pipeline to exist within the context of a single, running service. As such, some modules may depend upon one another, though in most cases, deployment modules should strictly depend on Kato's core module, which provides interfaces for deployment activities and name-keyed credential packs.

Kato comes pre-configured to work with IntelliJ IDEA. As such, the Gradle project will configure itself with appropriate IDEA workspace and project configuration files. Included in this configuration is the preferred per-project code style, the appropriate JDK language level settings, and the Netflix open source Apache License headers on all relevant files. To get started with the project in IntelliJ IDEA, simply execute the +gradle idea+ command in the project's top level.

=== Building

Kato can be built via command-line with either vanilla Gradle, or with Netflix's custom Nebula Gradle wrapper. While the latter is preferred, Kato has no strict requirement for this as part of the build process. To build, simply execute the +gradle build+ command in the project's root. This will produce a set of jar files in the +build/libs+ directories of the sub-projects. Kato's _web_ module specifies the Spring Boot Gradle plugin, so its jar file will be built as a so-called "fat-jar", capable of being run as a standalone archive.

Once built, the +web+ module may be used to act as a service endpoint, or the individuals project artifacts (including +web+) can be included as libraries in another web project.

=== Running

At its most fundamental level, Kato is but a set of libraries. Even its web tier is little more than a few controllers, which are capable of being mapped into another Spring project. This fact gives Kato a great deal of flexibility in _how_ it will be used in its implementation. The web subproject, however, is capable of acting as a standalone server, which bootstraps a Spring Application context within an embedded servlet container. By creating a run configuration within your IDE for the +com.netflix.asgard.kato.Main+ class, which is located within the +kato-web+ project module, you can run Kato in its embedded form.

In itself, however, the web project won't offer much functionality besides standing up an in-memory +NamedAccountCredentialsHolder+, which is responsible for the management and distribution of account credentials, bootstrapping +kato-core+'s no-operation deployment handler, and exposing the RESTful HTTP endpoints for the listing of available account credentials, the execution of atomic operations, and the retrieval of tasks that are being, or have been, executed.

== REST API

Kato provides a set of RESTful HTTP APIs, which expose its deployment-related functions (+/ops+), access to tasks that have run or are currently running (+/task+), and access to the list of configured account names, which can be used by descriptions to specify an account or environment with which a deployment-related activity should take place. 

=== Operations

Kato's REST API is driven off the premise that clients will provide a set of "descriptions" for the atomic operations which they wish to execute. Internally, POST'ed "descriptions" will be coerced to atomic operations, which will execute some deployment-related action against the operation's cloud provider. The service provides a RESTful HTTP endpoint at +/ops+, which takes an array of objects, where each object is keyed by the name of the operation that it is describing. For example, the request body shown in Listing 1.1 could be supplied to invoke the creation of an Amazon Elastic Load Balancer, the insertion of a DNS record at Route53, and the deployment of a given AMI to Amazon.

.Listing 1.1
[source,javascript]
----
POST /ops
[{
    "createAmazonLoadBalancerDescription": {
        "clusterName": "kato-main",
        "subnetType": "internal",
        "securityGroups": ["nf-infrastructure-vpc", "nf-datacenter-vpc"],
        "availabilityZones": {
            "us-east-1": []
        },
        "listeners": [{
            "externalProtocol": "TCP",
            "internalProtocol": "TCP",
            "externalPort": "7001",
            "internalPort": "7001"
        }],
        "credentials": "test"
    }
}, {
    "upsertAmazonDNSDescription": {
        "type": "CNAME",
        "name": "kato.test.netflix.net.",
        "hostedZoneName": "test.netflix.net.",
        "credentials": "test"
    }
}, {
    "basicAmazonDeployDescription": {
        "application": "kato",
        "amiName": "ami-xxxxxxxx",
        "stack": "main",
        "instanceType": "m1.medium",
        "securityGroups": ["nf-infrastructure-vpc", "nf-datacenter-vpc"],
        "subnetType": "internal",
        "availabilityZones": {
            "us-east-1": []
        },
        "capacity": {
            "min": 1,
            "max": 1,
            "desired": 1
        },
        "credentials": "test"
    }
}]
----

In this example, "createAmazonLoadBalancerDescription", "upsertAmazonDNSDescription", and "basicAmazonDeployDescription" are the names of the descriptions to which Kato can locate corresponding atomic operations (or "handlers"). The result from the above call will nearly always be a data structure that provides a RESTful HTTP reference link to a +Task+ resource, which can be polled by clients to see the status or history of a set of work they have submitted.

The response from a call to the operations endpoint will look like the JSON depicted in Listing 1.2.

.Listing 1.2
[source,javascript]
----
{ "id": "e1jbn3", "resourceLink": "/task/e1jbn3" }
----

It is the "resourceLink" piece of this response that defines the endpoint that clients can use to query the status of their job execution.

==== AWS Operations Module

Kato's AWS module (+kato-aws+) provides operations that are relevant for deployments and deployment-related function with Amazon.

===== **Basic Amazon Deploy Description**

_Key_: +basicAmazonDeployDescription+

This description supplies the +BasicAmazonDeployHandler+ with the inputs necessary to deploy a named Amazon Machine Image to a new AutoScaling Group.

.Description of payload inputs
[width="100%",frame="topbot",options="header,footer"]
|======================
|Key               | Type   | Required | Value
|application       | string | true     | The name of the application to which this deployment is concerned. Strictly speaking, this will be used to build the common naming scheme for the AutoScaling group
|amiName           | string | true     | Name of the AMI that will be deployed to the ASG.
|instanceType      | string | true     | Some https://aws.amazon.com/ec2/instance-types/[Amazon Instance Type] that members of this AutoScaling group will use.
|availabilityZones | object | true     | An object that provides a named region to array of availability zone relationships. For example, +{ "us-east-1": ["us-east-1a", "us-east-1c"] }+ will inform the deployment engine to deploy the provided AMI in the "us-east-1" region, and specifically into the availability zones: "us-east-1a", "us-east-1c".
|capacity          | object | true     | An object that represents the capacity of the newly created AutoScaling group. Valid values are "min", "max", and "desired", which represent the minimum number of instances, the maximum number of instances, and the desired number of instances for an AutoScaling group, respectively.
|securityGroups    | array  | false    | List of security *group names*. Their IDs in their particular regions will be found at Amazon -- no need to look them up in advance.
|loadBalancers     | array  | false    | A list of string values that correspond to load balancer names that should be attached to the newly created ASG. Load balancers must be created prior to this description being submitted. In the case where a +createAmazonLoadBalancerDescription+ was provided earlier in the request's execution chain, the value from that execution will be included in this list.
|subnetType        | string | false    | The subnet "type" that is applicable to this deployment. This instructs the deployment engine to what subnets and vpcs this deployment will be a part. Subnets that are tagged with the key "immutable_metadata" and a value of a structure like, +{ "purpose": "internal", "target": "ec2" }+, will be found by the engine, and their "purpose" may be used as a value type for this field. Note that "purpose" and "target" provide a composite key, where the "target" property has eligible values of one of: "ec2" or "elb". Only one "purpose" to "target" correlation is valid with respect to the "subnetType" field in this description.
|stack             | string | false    | The "stack" to which this deployment is applicable. A stack is some arbitrarily named "environment" that many applications may be a part of. This value, in conjunction with the "application" comprise the "cluster name" in Asgard's view of the Cloud.
|======================

=== Tasks

The endpoint mapped to +/task+ provides details about tasks that Kato has run or is running. When a description is submitted to Kato, it is transformed into an atomic operation and delegated to an orchestration engine, which will (should) process the request in the background, while returning a +Task+ object to the foreground. A response from a post to the operations controller will include a "resourceLink" to the task. That resource link can, in turn, be queried by clients to observe the current status of the submitted execution. An example output of a +DefaultTask+ object might look like the response shown in Listing 1.3.

.Listing 1.3
[source,javascript]
----
GET /task/e1jbn3
{
    "id": "e1jbn3",
    "phase": "AWS_DEPLOY",
    "status": "Deploying new AutoScaling group...",
    "complete": false,
    "failed": false,
    "startTimeMs": 1400011488500,
    "history": [{
        "phase": "ORCHESTRATION",
        "status": "Beginning orchestration"
    }, {
        "phase": "ORCHESTRATION",
        "status": "Invoking AWS Deploy handler..."
    }, {
        "phase": "AWS_DEPLOY",
        "status": "Deploying new AutoScalingGroup...."
    }]
}
----

Querying the +/task+ endpoint without supplying an ID means that a list of tasks -- both running and completed -- will be returned to the user.